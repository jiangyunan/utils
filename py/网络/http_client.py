import httpx
import asyncio
import socket
import time
import sqlite3
from typing import Dict, Tuple, Optional, ClassVar
import logging
from utils.logger import logger
# å…³é—­ç¬¬ä¸‰æ–¹åº“çš„ DEBUG æ—¥å¿—
logging.getLogger("httpcore").setLevel(logging.WARNING)
logging.getLogger("httpx").setLevel(logging.WARNING)
logging.getLogger("urllib3").setLevel(logging.WARNING)
logging.getLogger("asyncio").setLevel(logging.WARNING)

class PersistentDNSCache:
    """æŒä¹…åŒ– DNS ç¼“å­˜ç®¡ç†å™¨"""
    
    def __init__(self, db_path: str = "dns_cache.db"):
        self.db_path = db_path
        self._init_db()
    
    def _init_db(self):
        """åˆå§‹åŒ–æ•°æ®åº“"""
        conn = sqlite3.connect(self.db_path)
        cursor = conn.cursor()
        cursor.execute("""
            CREATE TABLE IF NOT EXISTS dns_cache (
                hostname TEXT PRIMARY KEY,
                ip TEXT NOT NULL,
                expire_time REAL NOT NULL,
                created_at REAL NOT NULL,
                updated_at REAL NOT NULL
            )
        """)
        conn.commit()
        conn.close()
        logger.info(f"âœ… DNS ç¼“å­˜æ•°æ®åº“åˆå§‹åŒ–å®Œæˆ: {self.db_path}")
    
    def get(self, hostname: str) -> Optional[str]:
        """è·å–ç¼“å­˜çš„ IP"""
        conn = sqlite3.connect(self.db_path)
        cursor = conn.cursor()
        
        cursor.execute(
            "SELECT ip, expire_time FROM dns_cache WHERE hostname = ?",
            (hostname,)
        )
        result = cursor.fetchone()
        conn.close()
        
        if result:
            ip, expire_time = result
            if time.time() < expire_time:
                logger.debug(f"âœ… DNS ç¼“å­˜å‘½ä¸­ (æ•°æ®åº“): {hostname} -> {ip}")
                return ip
            else:
                # è¿‡æœŸï¼Œåˆ é™¤
                self.delete(hostname)
                logger.info(f"â° DNS ç¼“å­˜è¿‡æœŸ (æ•°æ®åº“): {hostname}")
        
        return None
    
    def set(self, hostname: str, ip: str, ttl: int):
        """è®¾ç½® DNS ç¼“å­˜"""
        conn = sqlite3.connect(self.db_path)
        cursor = conn.cursor()
        
        expire_time = time.time() + ttl
        now = time.time()
        
        cursor.execute("""
            INSERT OR REPLACE INTO dns_cache 
            (hostname, ip, expire_time, created_at, updated_at)
            VALUES (?, ?, ?, ?, ?)
        """, (hostname, ip, expire_time, now, now))
        
        conn.commit()
        conn.close()
        logger.info(f"ğŸ’¾ DNS ç¼“å­˜å·²ä¿å­˜ (æ•°æ®åº“): {hostname} -> {ip} (TTL: {ttl}s)")
    
    def delete(self, hostname: str):
        """åˆ é™¤ç¼“å­˜"""
        conn = sqlite3.connect(self.db_path)
        cursor = conn.cursor()
        cursor.execute("DELETE FROM dns_cache WHERE hostname = ?", (hostname,))
        conn.commit()
        conn.close()
    
    def clear(self):
        """æ¸…ç©ºæ‰€æœ‰ç¼“å­˜"""
        conn = sqlite3.connect(self.db_path)
        cursor = conn.cursor()
        cursor.execute("DELETE FROM dns_cache")
        conn.commit()
        conn.close()
        logger.info("ğŸ§¹ DNS ç¼“å­˜å·²æ¸…ç©º (æ•°æ®åº“)")
    
    def cleanup_expired(self):
        """æ¸…ç†è¿‡æœŸç¼“å­˜"""
        conn = sqlite3.connect(self.db_path)
        cursor = conn.cursor()
        cursor.execute("DELETE FROM dns_cache WHERE expire_time < ?", (time.time(),))
        deleted = cursor.rowcount
        conn.commit()
        conn.close()
        if deleted > 0:
            logger.info(f"ğŸ§¹ æ¸…ç†äº† {deleted} æ¡è¿‡æœŸ DNS ç¼“å­˜")
        return deleted
    
    def get_stats(self) -> dict:
        """è·å–ç¼“å­˜ç»Ÿè®¡"""
        conn = sqlite3.connect(self.db_path)
        cursor = conn.cursor()
        
        # æ€»æ•°
        cursor.execute("SELECT COUNT(*) FROM dns_cache")
        total = cursor.fetchone()[0]
        
        # æœ‰æ•ˆæ•°é‡
        cursor.execute("SELECT COUNT(*) FROM dns_cache WHERE expire_time > ?", (time.time(),))
        valid = cursor.fetchone()[0]
        
        # è¯¦ç»†ä¿¡æ¯
        cursor.execute("SELECT hostname, ip, expire_time FROM dns_cache")
        domains = {}
        current_time = time.time()
        
        for hostname, ip, expire_time in cursor.fetchall():
            domains[hostname] = {
                "ip": ip,
                "expires_in": max(0, int(expire_time - current_time)),
                "is_valid": expire_time > current_time
            }
        
        conn.close()
        
        return {
            "total_cached": total,
            "valid_entries": valid,
            "expired_entries": total - valid,
            "domains": domains
        }



class HttpClient(httpx.AsyncClient):
    """å¸¦æŒä¹…åŒ– DNS ç¼“å­˜å’Œè‡ªåŠ¨é‡è¯•çš„ httpx.AsyncClient"""
    
    # ç±»çº§åˆ«çš„ç¼“å­˜ç®¡ç†å™¨
    _dns_cache: ClassVar[Optional[PersistentDNSCache]] = None
    _global_lock: ClassVar[asyncio.Lock] = None
    
    def __init__(self, dns_ttl: int = 600, dns_cache_db: str = "dns_cache.db", *args, **kwargs):
        """
        Args:
            dns_ttl: DNS ç¼“å­˜æ—¶é—´ï¼ˆç§’ï¼‰ï¼Œé»˜è®¤ 10 åˆ†é’Ÿ
            dns_cache_db: DNS ç¼“å­˜æ•°æ®åº“è·¯å¾„
        """
        super().__init__(*args, **kwargs)
        self.dns_ttl = dns_ttl
        
        # åˆå§‹åŒ–å…¨å±€ç¼“å­˜ç®¡ç†å™¨ï¼ˆåªåˆå§‹åŒ–ä¸€æ¬¡ï¼‰
        if HttpClient._dns_cache is None:
            HttpClient._dns_cache = PersistentDNSCache(dns_cache_db)
            HttpClient._dns_cache.cleanup_expired()  # å¯åŠ¨æ—¶æ¸…ç†è¿‡æœŸç¼“å­˜
        
        # åˆå§‹åŒ–å…¨å±€é”
        if HttpClient._global_lock is None:
            HttpClient._global_lock = asyncio.Lock()
        
        stats = self._dns_cache.get_stats()
        logger.info(f"âœ… HttpClient åˆå§‹åŒ–å®Œæˆ (ç¼“å­˜: {stats['valid_entries']}/{stats['total_cached']} æ¡æœ‰æ•ˆ)")
    
    async def _resolve_dns(self, hostname: str) -> Optional[str]:
        """è§£æ DNSï¼ˆä½¿ç”¨æŒä¹…åŒ–ç¼“å­˜ï¼‰"""
        async with self._global_lock:
            # æ£€æŸ¥ç¼“å­˜
            ip = self._dns_cache.get(hostname)
            if ip:
                return ip
            
            # DNS è§£æï¼ˆå¸¦é‡è¯•ï¼‰
            for attempt in range(3):
                try:
                    loop = asyncio.get_event_loop()
                    ip = await loop.run_in_executor(None, socket.gethostbyname, hostname)
                    
                    # å­˜å…¥æŒä¹…åŒ–ç¼“å­˜
                    self._dns_cache.set(hostname, ip, self.dns_ttl)
                    logger.info(f"ğŸ” DNS è§£ææˆåŠŸ: {hostname} -> {ip}")
                    return ip
                
                except socket.gaierror:
                    logger.warning(f"âŒ DNS è§£æå¤±è´¥ (å°è¯• {attempt+1}/3): {hostname}")
                    if attempt < 2:
                        await asyncio.sleep(2 ** attempt)
            
            return None
    
    async def request(self, method: str, url: str, max_retries: int = 3, 
                     retry_delay: float = 1.0, **kwargs) -> httpx.Response:
        """å‘é€ HTTP è¯·æ±‚ï¼ˆå¸¦è‡ªåŠ¨é‡è¯•ï¼‰"""
        from urllib.parse import urlparse, urlunparse
        
        parsed = urlparse(url)
        hostname = parsed.hostname
        
        # DNS è§£æ
        ip = await self._resolve_dns(hostname)
        if not ip:
            logger.error(f"âŒ DNS è§£æå¤±è´¥ï¼Œä½¿ç”¨åŸå§‹ URL: {url}")
            target_url = url
        else:
            # æ›¿æ¢ä¸»æœºåä¸º IP
            target_url = urlunparse((
                parsed.scheme,
                f"{ip}:{parsed.port}" if parsed.port else ip,
                parsed.path,
                parsed.params,
                parsed.query,
                parsed.fragment
            ))
            # è®¾ç½® Host å¤´
            if 'headers' not in kwargs:
                kwargs['headers'] = {}
            kwargs['headers']['Host'] = hostname
        
        # é‡è¯•é€»è¾‘
        last_error = None
        for attempt in range(max_retries):
            try:
                logger.info(f"ğŸš€ å‘é€è¯·æ±‚ (å°è¯• {attempt+1}/{max_retries}): {method} {target_url[:80]}...")
                response = await super().request(method, target_url, **kwargs)
                logger.info(f"âœ… è¯·æ±‚æˆåŠŸ: {response.status_code}")
                return response
            
            except (httpx.TimeoutException, httpx.ConnectError, httpx.RemoteProtocolError) as e:
                last_error = e
                logger.warning(f"âš ï¸ è¯·æ±‚å¤±è´¥ (å°è¯• {attempt+1}/{max_retries}): {e}")
                
                if attempt < max_retries - 1:
                    delay = retry_delay * (2 ** attempt)
                    logger.info(f"â³ ç­‰å¾… {delay} ç§’åé‡è¯•...")
                    await asyncio.sleep(delay)
        
        logger.error(f"âŒ è¯·æ±‚æœ€ç»ˆå¤±è´¥: {last_error}")
        raise last_error
    
    # ä¾¿æ·æ–¹æ³•
    async def get(self, url: str, **kwargs):
        return await self.request("GET", url, **kwargs)
    
    async def post(self, url: str, **kwargs):
        return await self.request("POST", url, **kwargs)
    
    async def put(self, url: str, **kwargs):
        return await self.request("PUT", url, **kwargs)
    
    async def delete(self, url: str, **kwargs):
        return await self.request("DELETE", url, **kwargs)
    
    @classmethod
    def clear_dns_cache(cls):
        """æ¸…ç©º DNS ç¼“å­˜"""
        if cls._dns_cache:
            cls._dns_cache.clear()
    
    @classmethod
    def cleanup_expired_dns(cls):
        """æ¸…ç†è¿‡æœŸ DNS ç¼“å­˜"""
        if cls._dns_cache:
            return cls._dns_cache.cleanup_expired()
        return 0
    
    @classmethod
    def get_dns_stats(cls) -> dict:
        """è·å– DNS ç¼“å­˜ç»Ÿè®¡"""
        if cls._dns_cache:
            return cls._dns_cache.get_stats()
        return {"total_cached": 0, "valid_entries": 0, "expired_entries": 0, "domains": {}}
